import argparse
import time
import json
import pickle
import io
import os
import socket
import threading
import tempfile
import struct
import sys
import psutil
import numpy as np
import tenso

# Optional dependencies for comparison
try:
    import msgpack
    import pyarrow as pa
    from safetensors.numpy import save as st_save, load as st_load
except ImportError:
    print("Warning: Missing benchmark dependencies (msgpack, pyarrow, safetensors). Some tests skipped.")

# --- HELPER: Resource Monitoring ---

class ResourceMonitor:
    """Monitor CPU and memory during benchmarks."""
    def __init__(self):
        self.process = psutil.Process()
        self.baseline_memory = self.process.memory_info().rss / 1024 / 1024
        
    def snapshot(self):
        return {
            'memory_mb': self.process.memory_info().rss / 1024 / 1024,
            'cpu_percent': self.process.cpu_percent()
        }
    
    def memory_delta(self):
        current = self.process.memory_info().rss / 1024 / 1024
        return current - self.baseline_memory

# --- 1. SERIALIZATION BENCHMARK HELPERS ---

def bench_json(data):
    enc = lambda x: json.dumps(x.tolist()).encode('utf-8')
    dec = lambda x: np.array(json.loads(x), dtype=data.dtype)
    return enc, dec

def bench_pickle(data):
    enc = lambda x: pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
    dec = lambda x: pickle.loads(x)
    return enc, dec

def bench_msgpack(data):
    enc = lambda x: msgpack.packb(x.tobytes())
    dec = lambda x: np.frombuffer(msgpack.unpackb(x), dtype=data.dtype).reshape(data.shape)
    return enc, dec

def bench_safetensors(data):
    def enc(x): return st_save({"t": x})
    def dec(x): return st_load(x)["t"]
    return enc, dec

def bench_arrow(data):
    def enc(x):
        arr = pa.array(x.flatten())
        batch = pa.RecordBatch.from_arrays([arr], names=['t'])
        sink = pa.BufferOutputStream()
        with pa.ipc.new_stream(sink, batch.schema) as writer:
            writer.write_batch(batch)
        return sink.getvalue()
    
    def dec(x):
        with pa.ipc.open_stream(x) as reader:
            batch = reader.read_next_batch()
            return batch.column(0).to_numpy(zero_copy_only=False).reshape(data.shape)
    return enc, dec

def bench_tenso(data):
    return tenso.dumps, tenso.loads

# --- BENCHMARK RUNNERS ---

def run_serialization():
    print("\n" + "="*80)
    print("BENCHMARK 1: IN-MEMORY SERIALIZATION (CPU Overhead)")
    print("="*80)
    
    SCENARIOS = [
        {"name": "API Vector", "shape": (1536,), "dtype": np.float32},
        {"name": "CV Batch", "shape": (32, 256, 256, 3), "dtype": np.uint8},
        {"name": "LLM Layer", "shape": (4096, 4096), "dtype": np.float32}
    ]
    
    print(f"{'SCENARIO':<15} | {'FORMAT':<12} | {'SIZE':<10} | {'SERIALIZE':<10} | {'DESERIALIZE':<10}")
    print("-" * 75)

    for scen in SCENARIOS:
        if scen['dtype'] == np.uint8:
            data = np.random.randint(0, 255, scen['shape']).astype(np.uint8)
        else:
            data = np.random.rand(*scen['shape']).astype(scen['dtype'])
        
        competitors = {
            "Pickle": bench_pickle(data),
            "Tenso": bench_tenso(data)
        }
        if 'msgpack' in globals(): competitors["MsgPack"] = bench_msgpack(data)
        if 'st_save' in globals(): competitors["Safetensors"] = bench_safetensors(data)
        if 'pa' in globals(): competitors["Arrow"] = bench_arrow(data)

        for name, (enc_func, dec_func) in competitors.items():
            try:
                # Warmup
                encoded = enc_func(data)
                _ = dec_func(encoded)
                
                ITERATIONS = 10
                t0 = time.perf_counter()
                for _ in range(ITERATIONS): encoded = enc_func(data)
                t_ser = ((time.perf_counter() - t0) / ITERATIONS) * 1000

                t0 = time.perf_counter()
                for _ in range(ITERATIONS): _ = dec_func(encoded)
                t_des = ((time.perf_counter() - t0) / ITERATIONS) * 1000
                
                size_str = f"{len(encoded)/1024/1024:.2f} MB" if len(encoded) > 1024**2 else f"{len(encoded)/1024:.2f} KB"
                print(f"{scen['name']:<15} | {name:<12} | {size_str:<10} | {t_ser:>7.3f} ms | {t_des:>7.3f} ms")
            except Exception as e:
                print(f"{scen['name']:<15} | {name:<12} | FAILED ({e})")
        print("-" * 75)

def run_io():
    print("\n" + "="*80)
    print("BENCHMARK 2: DISK I/O (Read/Write & Memory Mapping)")
    print("="*80)
    
    shape = (8192, 8192) 
    data = np.random.rand(*shape).astype(np.float32)
    size_mb = data.nbytes / (1024 * 1024)
    print(f"Dataset: {size_mb:.0f} MB Matrix {shape}")
    
    print(f"{'FORMAT':<15} | {'WRITE (ms)':<10} | {'READ (ms)':<10}")
    print("-" * 60)

    # 1. Tenso
    with tempfile.NamedTemporaryFile(delete=False) as f: path = f.name
    try:
        t0 = time.perf_counter()
        with open(path, "wb") as f: tenso.dump(data, f)
        t_write = (time.perf_counter() - t0) * 1000

        t0 = time.perf_counter()
        with open(path, "rb") as f: tenso.load(f, mmap_mode=True)
        t_read = (time.perf_counter() - t0) * 1000
        print(f"{'Tenso':<15} | {t_write:>10.2f} | {t_read:>10.2f}")
    finally: os.remove(path)

    # 2. Numpy
    with tempfile.NamedTemporaryFile(delete=False, suffix='.npy') as f: path = f.name
    try:
        t0 = time.perf_counter()
        np.save(path, data)
        t_write = (time.perf_counter() - t0) * 1000

        t0 = time.perf_counter()
        np.load(path, mmap_mode='r')
        t_read = (time.perf_counter() - t0) * 1000
        print(f"{'Numpy .npy':<15} | {t_write:>10.2f} | {t_read:>10.2f}")
    finally: os.remove(path)

    # 3. Pickle
    with tempfile.NamedTemporaryFile(delete=False) as f: path = f.name
    try:
        t0 = time.perf_counter()
        with open(path, "wb") as f: pickle.dump(data, f)
        t_write = (time.perf_counter() - t0) * 1000

        with open(path, "rb") as f: 
            t0 = time.perf_counter()
            pickle.load(f)
            t_read = (time.perf_counter() - t0) * 1000
        print(f"{'Pickle':<15} | {t_write:>10.2f} | {t_read:>10.2f}")
    finally: os.remove(path)

def run_stream_read():
    print("\n" + "="*80)
    print("BENCHMARK 3: STREAM READ (Throughput & Memory Churn)")
    print("="*80)
    
    class FastStream(io.BytesIO): pass # IOBase supports readinto
    
    data = np.random.rand(5000, 5000).astype(np.float32)
    packet = tenso.dumps(data)
    size_mb = len(packet) / (1024 * 1024)
    
    print(f"Dataset: {size_mb:.0f} MB Packet")
    print(f"{'METHOD':<20} | {'TIME (ms)':<10} | {'THROUGHPUT':<15}")
    print("-" * 60)

    # Optimized
    stream = FastStream(packet)
    t0 = time.perf_counter()
    tenso.read_stream(stream)
    t_opt = (time.perf_counter() - t0) * 1000
    print(f"{'Tenso read_stream':<20} | {t_opt:>7.2f} ms | {size_mb/(t_opt/1000):>7.2f} MB/s")

    # Legacy Loop Simulation
    stream.seek(0)
    t0 = time.perf_counter()
    buffer = b''
    while True:
        chunk = stream.read(65536)
        if not chunk: break
        buffer += chunk
    tenso.loads(buffer)
    t_old = (time.perf_counter() - t0) * 1000
    print(f"{'Naive Loop':<20} | {t_old:>7.2f} ms | {size_mb/(t_old/1000):>7.2f} MB/s")
    
    print("-" * 60)
    print(f"Speedup: {t_old/t_opt:.1f}x")

def run_stream_write():
    print("\n" + "="*80)
    print("BENCHMARK 4: NETWORK WRITE (Latency & Atomic Packets)")
    print("="*80)
    
    PORT = 9998
    
    def sink_server():
        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        s.bind(('localhost', PORT))
        s.listen(1)
        conn, _ = s.accept()
        while True:
            try:
                if not conn.recv(1024*1024): break
            except: break
        conn.close()
        s.close()

    t = threading.Thread(target=sink_server, daemon=True)
    t.start()
    time.sleep(0.5)

    client = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    client.connect(('localhost', PORT))

    data = np.random.rand(16, 16).astype(np.float32)
    COUNT = 10000
    
    print(f"Sending {COUNT} tensors (1KB each) over localhost TCP...")

    # Optimized write_stream
    t0 = time.perf_counter()
    for _ in range(COUNT):
        tenso.write_stream(data, client)
    t_total = time.perf_counter() - t0
    
    client.close()
    
    print(f"Total Time: {t_total:.4f}s")
    print(f"Throughput: {COUNT/t_total:.0f} packets/sec")
    print(f"Latency:    {(t_total/COUNT)*1_000_000:.1f} µs/packet")

def run_memory_overhead():
    """NEW: Benchmark memory overhead of different formats."""
    print("\n" + "="*80)
    print("BENCHMARK 5: MEMORY OVERHEAD (Serialization Overhead)")
    print("="*80)
    
    shapes = [
        (1000, 1000),
        (2000, 2000), 
        (4000, 4000)
    ]
    
    print(f"{'SIZE':<15} | {'FORMAT':<12} | {'RAW (MB)':<10} | {'SERIALIZED (MB)':<15} | {'OVERHEAD':<10}")
    print("-" * 80)
    
    for shape in shapes:
        data = np.random.rand(*shape).astype(np.float32)
        raw_size = data.nbytes / 1024 / 1024
        
        results = {}
        
        # Tenso
        packet = tenso.dumps(data)
        results['Tenso'] = len(packet) / 1024 / 1024
        
        # Pickle
        packet = pickle.dumps(data, protocol=pickle.HIGHEST_PROTOCOL)
        results['Pickle'] = len(packet) / 1024 / 1024
        
        # Arrow
        if 'pa' in globals():
            arr = pa.array(data.flatten())
            batch = pa.RecordBatch.from_arrays([arr], names=['t'])
            sink = pa.BufferOutputStream()
            with pa.ipc.new_stream(sink, batch.schema) as writer:
                writer.write_batch(batch)
            results['Arrow'] = len(sink.getvalue()) / 1024 / 1024
        
        # SafeTensors
        if 'st_save' in globals():
            packet = st_save({"t": data})
            results['Safetensors'] = len(packet) / 1024 / 1024
        
        for name, size in results.items():
            overhead = ((size - raw_size) / raw_size) * 100
            print(f"{str(shape):<15} | {name:<12} | {raw_size:>8.2f} | {size:>13.2f} | {overhead:>8.2f}%")
        
        print("-" * 80)

def run_cpu_usage():
    """NEW: Measure CPU usage during serialization/deserialization."""
    print("\n" + "="*80)
    print("BENCHMARK 6: CPU USAGE (Resource Efficiency)")
    print("="*80)
    
    data = np.random.rand(4096, 4096).astype(np.float32)
    monitor = ResourceMonitor()
    
    print(f"{'FORMAT':<15} | {'SERIALIZE CPU%':<15} | {'DESERIALIZE CPU%':<18}")
    print("-" * 60)
    
    formats = {
        'Tenso': (tenso.dumps, tenso.loads),
        'Pickle': (lambda x: pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL), pickle.loads)
    }
    
    if 'pa' in globals():
        def arrow_enc(x):
            arr = pa.array(x.flatten())
            batch = pa.RecordBatch.from_arrays([arr], names=['t'])
            sink = pa.BufferOutputStream()
            with pa.ipc.new_stream(sink, batch.schema) as writer:
                writer.write_batch(batch)
            return sink.getvalue()
        
        def arrow_dec(x):
            with pa.ipc.open_stream(x) as reader:
                batch = reader.read_next_batch()
                return batch.column(0).to_numpy(zero_copy_only=False).reshape(data.shape)
        
        formats['Arrow'] = (arrow_enc, arrow_dec)
    
    if 'st_save' in globals():
        formats['Safetensors'] = (lambda x: st_save({"t": x}), lambda x: st_load(x)["t"])
    
    for name, (enc, dec) in formats.items():
        # Warmup
        packet = enc(data)
        _ = dec(packet)
        
        # Measure serialization CPU
        monitor.process.cpu_percent()  # Reset
        time.sleep(0.1)
        for _ in range(20):
            _ = enc(data)
        ser_cpu = monitor.process.cpu_percent()
        
        # Measure deserialization CPU
        monitor.process.cpu_percent()  # Reset
        time.sleep(0.1)
        for _ in range(20):
            _ = dec(packet)
        des_cpu = monitor.process.cpu_percent()
        
        print(f"{name:<15} | {ser_cpu:>13.1f}% | {des_cpu:>16.1f}%")

def run_dtype_coverage():
    """NEW: Test all supported dtypes."""
    print("\n" + "="*80)
    print("BENCHMARK 7: DTYPE COVERAGE (Compatibility Test)")
    print("="*80)
    
    dtypes = [
        np.float16, np.float32, np.float64,
        np.int8, np.int16, np.int32, np.int64,
        np.uint8, np.uint16, np.uint32, np.uint64,
        np.bool_, np.complex64, np.complex128
    ]
    
    shape = (100, 100)
    
    print(f"{'DTYPE':<15} | {'STATUS':<10} | {'SIZE (KB)':<12} | {'ROUNDTRIP (ms)':<15}")
    print("-" * 65)
    
    for dtype in dtypes:
        try:
            if dtype == np.bool_:
                data = np.random.randint(0, 2, shape).astype(dtype)
            elif np.issubdtype(dtype, np.integer):
                data = np.random.randint(0, 100, shape).astype(dtype)
            elif np.issubdtype(dtype, np.complexfloating):
                real = np.random.randn(*shape)
                imag = np.random.randn(*shape)
                data = (real + 1j * imag).astype(dtype)
            else:
                data = np.random.randn(*shape).astype(dtype)
            
            t0 = time.perf_counter()
            packet = tenso.dumps(data)
            restored = tenso.loads(packet)
            roundtrip = (time.perf_counter() - t0) * 1000
            
            if np.array_equal(data, restored):
                status = "✓ PASS"
            else:
                status = "✗ FAIL"
            
            size_kb = len(packet) / 1024
            print(f"{str(dtype):<15} | {status:<10} | {size_kb:>10.2f} | {roundtrip:>13.3f}")
            
        except Exception as e:
            print(f"{str(dtype):<15} | {'✗ ERROR':<10} | {'-':<12} | {str(e)[:20]}")
    
    print("-" * 65)

def run_arrow_comparison():
    """NEW: Detailed Arrow vs Tenso comparison."""
    print("\n" + "="*80)
    print("BENCHMARK 8: ARROW vs TENSO (Head-to-Head)")
    print("="*80)
    
    if 'pa' not in globals():
        print("Arrow not available. Skipping.")
        return
    
    sizes = [
        ("Small", (512, 512)),
        ("Medium", (2048, 2048)),
        ("Large", (4096, 4096)),
        ("XLarge", (8192, 8192))
    ]
    
    print(f"{'SIZE':<10} | {'TENSO SER':<12} | {'ARROW SER':<12} | {'TENSO DES':<12} | {'ARROW DES':<12} | {'SPEEDUP':<10}")
    print("-" * 95)
    
    for name, shape in sizes:
        data = np.random.rand(*shape).astype(np.float32)
        
        # Tenso
        t0 = time.perf_counter()
        tenso_packet = tenso.dumps(data)
        tenso_ser = (time.perf_counter() - t0) * 1000
        
        t0 = time.perf_counter()
        _ = tenso.loads(tenso_packet)
        tenso_des = (time.perf_counter() - t0) * 1000
        
        # Arrow
        arr = pa.array(data.flatten())
        batch = pa.RecordBatch.from_arrays([arr], names=['t'])
        
        t0 = time.perf_counter()
        sink = pa.BufferOutputStream()
        with pa.ipc.new_stream(sink, batch.schema) as writer:
            writer.write_batch(batch)
        arrow_packet = sink.getvalue()
        arrow_ser = (time.perf_counter() - t0) * 1000
        
        t0 = time.perf_counter()
        with pa.ipc.open_stream(arrow_packet) as reader:
            batch = reader.read_next_batch()
            _ = batch.column(0).to_numpy(zero_copy_only=False).reshape(shape)
        arrow_des = (time.perf_counter() - t0) * 1000
        
        speedup = arrow_des / tenso_des
        
        print(f"{name:<10} | {tenso_ser:>10.3f}ms | {arrow_ser:>10.3f}ms | {tenso_des:>10.3f}ms | {arrow_des:>10.3f}ms | {speedup:>8.1f}x")
    
    print("-" * 95)

def run_correctness():
    """NEW: Verify data integrity."""
    print("\n" + "="*80)
    print("BENCHMARK 9: CORRECTNESS (Data Integrity)")
    print("="*80)
    
    tests = [
        ("Zeros", lambda: np.zeros((100, 100), dtype=np.float32)),
        ("Ones", lambda: np.ones((100, 100), dtype=np.float32)),
        ("Random", lambda: np.random.rand(100, 100).astype(np.float32)),
        ("Negative", lambda: -np.random.rand(100, 100).astype(np.float32)),
        ("Mixed", lambda: np.random.randn(100, 100).astype(np.float32)),
        ("Large Values", lambda: np.random.rand(100, 100).astype(np.float32) * 1e6),
        ("Small Values", lambda: np.random.rand(100, 100).astype(np.float32) * 1e-6),
    ]
    
    print(f"{'TEST':<20} | {'STATUS':<10} | {'MAX ERROR':<15}")
    print("-" * 55)
    
    for name, gen_func in tests:
        data = gen_func()
        packet = tenso.dumps(data)
        restored = tenso.loads(packet)
        
        if np.allclose(data, restored, rtol=1e-7, atol=1e-7):
            max_error = np.abs(data - restored).max()
            print(f"{name:<20} | {'✓ PASS':<10} | {max_error:<15.2e}")
        else:
            print(f"{name:<20} | {'✗ FAIL':<10} | {'MISMATCH':<15}")
    
    print("-" * 55)

def print_summary():
    """Print system info and summary."""
    print("\n" + "="*80)
    print("SYSTEM INFORMATION")
    print("="*80)
    print(f"Python Version: {sys.version.split()[0]}")
    print(f"NumPy Version:  {np.__version__}")
    print(f"Tenso Version:  {tenso.__version__ if hasattr(tenso, '__version__') else 'unknown'}")
    print(f"CPU Cores:      {psutil.cpu_count()}")
    print(f"Total Memory:   {psutil.virtual_memory().total / 1024**3:.1f} GB")
    print(f"Platform:       {sys.platform}")
    
    if 'pa' in globals():
        print(f"Arrow Version:  {pa.__version__}")
    print("="*80)

# --- MAIN ---

if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Tenso Comprehensive Benchmarks",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Benchmark Modes:
  all         - Run all benchmarks (default)
  ser         - Serialization speed
  io          - Disk I/O performance
  read        - Stream reading
  write       - Network writing
  memory      - Memory overhead
  cpu         - CPU usage
  dtypes      - Dtype coverage
  arrow       - Arrow comparison
  correctness - Data integrity
  quick       - Quick overview (ser + arrow)
        """
    )
    
    parser.add_argument(
        "mode", 
        nargs="?", 
        choices=["all", "ser", "io", "read", "write", "memory", "cpu", "dtypes", "arrow", "correctness", "quick"], 
        default="all",
        help="Benchmark mode to run"
    )
    
    parser.add_argument(
        "--no-summary",
        action="store_true",
        help="Skip system information summary"
    )
    
    args = parser.parse_args()
    
    if not args.no_summary:
        print_summary()
    
    if args.mode == "all":
        run_serialization()
        run_io()
        run_stream_read()
        run_stream_write()
        run_memory_overhead()
        run_cpu_usage()
        run_dtype_coverage()
        run_arrow_comparison()
        run_correctness()
    elif args.mode == "quick":
        run_serialization()
        run_arrow_comparison()
    elif args.mode == "ser":
        run_serialization()
    elif args.mode == "io":
        run_io()
    elif args.mode == "read":
        run_stream_read()
    elif args.mode == "write":
        run_stream_write()
    elif args.mode == "memory":
        run_memory_overhead()
    elif args.mode == "cpu":
        run_cpu_usage()
    elif args.mode == "dtypes":
        run_dtype_coverage()
    elif args.mode == "arrow":
        run_arrow_comparison()
    elif args.mode == "correctness":
        run_correctness()
    
    print("\n" + "="*80)
    print("BENCHMARKS COMPLETE")
    print("="*80)